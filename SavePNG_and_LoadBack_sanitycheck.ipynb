{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import PIL\n",
    "from PIL import Image, ImageSequence, ImageOps\n",
    "import sys\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashing_lookup(original_study_name, hashed_mrn_table):\n",
    "    '''\n",
    "    '11081934s1' etc\n",
    "    '''\n",
    "    \n",
    "    mrn, study_idx = original_study_name.split('s')\n",
    "    \n",
    "    hashed_mrn = str(hashed_mrn_table[hashed_mrn_table['original_mrn']==int(mrn)].hashed_mrn.values[0])\n",
    "    hashed_study_name = 's'.join([hashed_mrn, study_idx])\n",
    "    \n",
    "    return hashed_study_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_pad(tiff_image, resized_shape):\n",
    "    \n",
    "    this_tiff_image_original_height = tiff_image.size[1]\n",
    "    this_tiff_image_original_width = tiff_image.size[0]\n",
    "    \n",
    "    if this_tiff_image_original_height > this_tiff_image_original_width:\n",
    "        \n",
    "        this_tiff_image_new_height = resized_shape\n",
    "        this_tiff_image_new_width = int(resized_shape * (this_tiff_image_original_width/this_tiff_image_original_height))\n",
    "        \n",
    "        pad_along_width = resized_shape - this_tiff_image_new_width\n",
    "        pad_along_height = 0\n",
    "        \n",
    "        pad_configuration = ((0, pad_along_height), (0, pad_along_width), (0,0)) \n",
    "    \n",
    "    elif this_tiff_image_original_height <= this_tiff_image_original_width:\n",
    "        \n",
    "        this_tiff_image_new_width = resized_shape\n",
    "        this_tiff_image_new_height = int(resized_shape * (this_tiff_image_original_height/this_tiff_image_original_width))\n",
    "        \n",
    "        pad_along_height = resized_shape - this_tiff_image_new_height\n",
    "        pad_along_width = 0\n",
    "        \n",
    "        pad_configuration = ((0, pad_along_height), (0, pad_along_width), (0,0))\n",
    "    \n",
    "    return this_tiff_image_new_height, this_tiff_image_new_width, pad_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_integer_mapping_dir=\"/cluster/tufts/hugheslab/zhuang12/Echo_ClinicalManualScript_1112/split_info\"\n",
    "resized_shape=112\n",
    "ImageList_fullpaths = \"/cluster/tufts/hugheslab/zhuang12/Echo_ClinicalManualScript_1112/split_info_regenerate_for_data_release_convenience_v2/seed0/shared_test_this_seed/test.csv\"\n",
    "result_save_dir = './sample_images'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3602 [00:00<01:49, 32.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently reading /cluster/tufts/hugheslab/zhuang12/Echo_ClinicalManualScript_1112/split_info_regenerate_for_data_release_convenience_v2/seed0/shared_test_this_seed/test.csv\n",
      "#images to extract: 3602\n",
      "initial current_study: 5269s1\n",
      "current_study: 5269s1\n",
      "this_study: 5269s1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "hashed_mrn_table = pd.read_csv('/cluster/tufts/hugheslab/zhuang12/JACC_DataRelease/20220412version/MRN_hashing_table_20220412.csv')\n",
    "\n",
    "make_dir_if_not_exists(result_save_dir)\n",
    "\n",
    "with open(os.path.join(class_to_integer_mapping_dir, 'view_class_to_integer_mapping.json')) as view_file:\n",
    "        view_class_to_integer_mapping = json.load(view_file)\n",
    "    \n",
    "with open(os.path.join(class_to_integer_mapping_dir, 'diagnosis_class_to_integer_mapping.json')) as diagnosis_file:\n",
    "    diagnosis_class_to_integer_mapping = json.load(diagnosis_file)\n",
    "    \n",
    "    \n",
    "this_ImageList = None\n",
    "ImageList_fullpaths = ImageList_fullpaths.split(',')\n",
    "for ImageList_fullpath in ImageList_fullpaths: \n",
    "    print('Currently reading {}'.format(ImageList_fullpath))\n",
    "    this_ImageList = pd.concat([this_ImageList, pd.read_csv(ImageList_fullpath)], ignore_index=True)\n",
    "\n",
    "\n",
    "this_ImageList = this_ImageList.sort_values(by=['study_names'])\n",
    "num_images_to_extract = this_ImageList.shape[0]\n",
    "print('#images to extract: {}'.format(num_images_to_extract))\n",
    "\n",
    "global_count = 0\n",
    "\n",
    "#initialize the first current study\n",
    "current_study = hashing_lookup(this_ImageList.iloc[0].study_names.split('_')[0], hashed_mrn_table)\n",
    "print('initial current_study: {}'.format(current_study))\n",
    "current_study_count = 0\n",
    "\n",
    "for i in trange(num_images_to_extract):\n",
    "    if global_count==1:\n",
    "        break\n",
    "    \n",
    "    print('current_study: {}'.format(current_study))\n",
    "    this_tiff_fullpath = this_ImageList.iloc[i].tiff_paths\n",
    "    this_tiff_viewlabel = this_ImageList.iloc[i].view_labels\n",
    "    this_tiff_diagnosislabel = this_ImageList.iloc[i].diagnosis_labels\n",
    "\n",
    "    this_study = hashing_lookup(this_ImageList.iloc[i].study_names.split('_')[0], hashed_mrn_table)\n",
    "\n",
    "    print('this_study: {}'.format(this_study))\n",
    "    if this_study == current_study:\n",
    "        current_study_count += 1\n",
    "    else:\n",
    "        current_study = this_study\n",
    "        current_study_count = 1\n",
    "\n",
    "    im = Image.open(this_tiff_fullpath)\n",
    "\n",
    "    #the ImageList already dont contain broken tiff, so don't need to use exception\n",
    "    for page, tiff_image in enumerate(ImageSequence.Iterator(im)):\n",
    "        if page == 1: #only take the first frame\n",
    "            break\n",
    "            \n",
    "    #convert to grayscale\n",
    "    tiff_image = ImageOps.grayscale(tiff_image) #convert to gray scale\n",
    "    #resize\n",
    "    this_tiff_image_new_height, this_tiff_image_new_width, pad_configuration = resize_and_pad(tiff_image, resized_shape)\n",
    "\n",
    "    tiff_image = tiff_image.resize((this_tiff_image_new_width, this_tiff_image_new_height))\n",
    "\n",
    "    #expand from (H,W) to (H,W,1)\n",
    "    tiff_image_array = np.expand_dims(np.array(tiff_image), axis=2)\n",
    "\n",
    "    #pad\n",
    "    tiff_image_array = np.pad(tiff_image_array, pad_width=pad_configuration, mode='constant', constant_values=0)        \n",
    "\n",
    "    im_to_save = Image.fromarray(tiff_image_array.squeeze())\n",
    "        \n",
    "#     if os.path.exists(\"{}/{}_{}.png\".format(result_save_dir, this_study, current_study_count-1)):\n",
    "#         print(\"{}/{}_{}.png\".format(result_save_dir, this_study, current_study_count-1))\n",
    "#         raise NameError('file already exists')\n",
    "\n",
    "    im_to_save.save(\"{}/{}_{}.png\".format(result_save_dir, this_study, current_study_count-1))\n",
    "    global_count +=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiff_image_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load back as np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImage(file_path):\n",
    "    im = PIL.Image.open(file_path)\n",
    "    im = np.asarray(im)\n",
    "    return im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_image_array_loadback = LoadImage('./sample_images/5269s1_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiff_image_array_loadback.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check array equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(tiff_image_array_loadback, tiff_image_array.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
